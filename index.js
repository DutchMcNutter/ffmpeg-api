const { exec } = require('child_process');
const fs = require('fs').promises;
const axios = require('axios');
const FormData = require('form-data');
const fsSync = require('fs');

const OPENAI_API_KEY = process.env.OPENAI_API_KEY;

// Lambda handler function
exports.handler = async (event) => {
  const startTime = Date.now();
  console.log('ðŸŽ¬ New video processing request received');
  
  try {
    // Parse request body (Lambda passes it as string)
    let body;
    if (typeof event.body === 'string') {
      body = JSON.parse(event.body);
    } else {
      body = event.body || {};
    }
    
    // Handle health check
    if (event.rawPath === '/health' || event.path === '/health') {
      return {
        statusCode: 200,
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ 
          status: 'ok', 
          message: 'FFmpeg Lambda is running',
          timestamp: new Date().toISOString()
        })
      };
    }
    
    const { videoUrl, includeZoom = true } = body;
    
    if (!videoUrl) {
      return {
        statusCode: 400,
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ error: 'videoUrl is required' })
      };
    }
    
    if (!OPENAI_API_KEY) {
      return {
        statusCode: 500,
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ error: 'OPENAI_API_KEY not configured' })
      };
    }
    
    // Generate unique filenames
    const timestamp = Date.now();
    const inputVideo = `/tmp/input_${timestamp}.mp4`;
    const audioFile = `/tmp/audio_${timestamp}.mp3`;
    const srtFile = `/tmp/captions_${timestamp}.srt`;
    const outputVideo = `/tmp/output_${timestamp}.mp4`;
    
    console.log('ðŸ“¥ Downloading video from HeyGen...');
    // Download video
    const response = await axios.get(videoUrl, { 
      responseType: 'arraybuffer',
      timeout: 60000
    });
    await fs.writeFile(inputVideo, response.data);
    console.log('âœ… Video downloaded successfully');
    
    // Extract audio
    console.log('ðŸŽµ Extracting audio...');
    await execPromise(`ffmpeg -i ${inputVideo} -vn -acodec libmp3lame -q:a 2 ${audioFile}`);
    console.log('âœ… Audio extracted');
    
    // Transcribe with Whisper
    console.log('ðŸŽ¤ Transcribing audio with Whisper...');
    const transcription = await transcribeAudio(audioFile);
    console.log('âœ… Transcription complete');
    
    // Convert to SRT with 2-3 word chunks
    console.log('ðŸ“ Creating caption file...');
    const srtContent = createSRTFile(transcription);
    await fs.writeFile(srtFile, srtContent);
    console.log('âœ… SRT file created');
    
    // Build FFmpeg command with captions and optional zoom
    console.log('ðŸŽ¥ Processing video with captions and effects...');
    let filterComplex = '';
    
    if (includeZoom) {
      // Add random zoom effect (zooms in and out every 10-15 seconds)
      filterComplex = `[0:v]zoompan=z='if(lte(mod(time,12),6),min(1.5,1+(time-floor(time/12)*12)/6*0.5),max(1,1.5-(time-floor(time/12)*12-6)/6*0.5))':d=1:s=1080x1920:fps=30,subtitles=${srtFile}:force_style='FontName=Arial Bold,FontSize=28,PrimaryColour=&H00FFFF,OutlineColour=&H000000,Outline=3,Bold=1,Alignment=2,MarginV=80'[v]`;
    } else {
      filterComplex = `[0:v]subtitles=${srtFile}:force_style='FontName=Arial Bold,FontSize=28,PrimaryColour=&H00FFFF,OutlineColour=&H000000,Outline=3,Bold=1,Alignment=2,MarginV=80'[v]`;
    }
    
    const ffmpegCommand = `ffmpeg -i ${inputVideo} -filter_complex "${filterComplex}" -map "[v]" -map 0:a -c:v libx264 -preset fast -crf 23 -c:a aac ${outputVideo}`;
    
    await execPromise(ffmpegCommand);
    console.log('âœ… Video processing complete');
    
    // Read processed video and convert to base64
    console.log('ðŸ“¤ Preparing response...');
    const videoBuffer = await fs.readFile(outputVideo);
    const base64Video = videoBuffer.toString('base64');
    
    // Cleanup temporary files
    console.log('ðŸ§¹ Cleaning up temporary files...');
    await Promise.all([
      fs.unlink(inputVideo).catch(() => {}),
      fs.unlink(audioFile).catch(() => {}),
      fs.unlink(srtFile).catch(() => {}),
      fs.unlink(outputVideo).catch(() => {})
    ]);
    
    const processingTime = ((Date.now() - startTime) / 1000).toFixed(2);
    console.log(`âœ… Processing complete in ${processingTime} seconds`);
    
    return {
      statusCode: 200,
      headers: { 
        'Content-Type': 'application/json',
        'Access-Control-Allow-Origin': '*'
      },
      body: JSON.stringify({
        success: true,
        video: base64Video,
        metadata: {
          processingTimeSeconds: parseFloat(processingTime),
          videoSizeKB: Math.round(videoBuffer.length / 1024),
          captionsAdded: true,
          zoomEffectApplied: includeZoom
        }
      })
    };
    
  } catch (error) {
    console.error('âŒ Error processing video:', error);
    return {
      statusCode: 500,
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ 
        error: error.message,
        details: error.toString()
      })
    };
  }
};

// Helper function to execute shell commands as promises
function execPromise(command) {
  return new Promise((resolve, reject) => {
    exec(command, { maxBuffer: 50 * 1024 * 1024 }, (error, stdout, stderr) => {
      if (error) {
        reject(error);
      } else {
        resolve(stdout);
      }
    });
  });
}

// Transcribe audio using OpenAI Whisper
async function transcribeAudio(audioFilePath) {
  const formData = new FormData();
  formData.append('file', fsSync.createReadStream(audioFilePath));
  formData.append('model', 'whisper-1');
  formData.append('response_format', 'verbose_json');
  formData.append('timestamp_granularities[]', 'word');
  
  const response = await axios.post(
    'https://api.openai.com/v1/audio/transcriptions',
    formData,
    {
      headers: {
        'Authorization': `Bearer ${OPENAI_API_KEY}`,
        ...formData.getHeaders()
      },
      timeout: 60000
    }
  );
  
  return response.data;
}

// Create SRT file with 2-3 word chunks
function createSRTFile(transcription) {
  const words = transcription.words || [];
  let srtContent = '';
  let index = 1;
  
  // Group words into chunks of 2-3 words
  const chunkSize = 3;
  for (let i = 0; i < words.length; i += chunkSize) {
    const chunk = words.slice(i, i + chunkSize);
    if (chunk.length === 0) continue;
    
    const startTime = formatTimestamp(chunk[0].start);
    const endTime = formatTimestamp(chunk[chunk.length - 1].end);
    const text = chunk.map(w => w.word).join(' ');
    
    srtContent += `${index}\n`;
    srtContent += `${startTime} --> ${endTime}\n`;
    srtContent += `${text}\n\n`;
    index++;
  }
  
  return srtContent;
}

// Format timestamp for SRT (HH:MM:SS,mmm)
function formatTimestamp(seconds) {
  const hours = Math.floor(seconds / 3600);
  const minutes = Math.floor((seconds % 3600) / 60);
  const secs = Math.floor(seconds % 60);
  const milliseconds = Math.floor((seconds % 1) * 1000);
  
  return `${String(hours).padStart(2, '0')}:${String(minutes).padStart(2, '0')}:${String(secs).padStart(2, '0')},${String(milliseconds).padStart(3, '0')}`;
}
